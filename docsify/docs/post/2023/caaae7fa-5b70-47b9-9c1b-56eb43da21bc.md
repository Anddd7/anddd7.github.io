# AI 是个筐啥都可以装 - 图解 AI 基本概念

> GPT 是什么？  
> 生成式 AI 是什么样的 AI？还有非生成式的吗？  
> 人工智能研究了这么多年 ChatGPT 为什么2022 年才进入公众视野？

## 背景

在过去的半年，人工智能不再只是学术论文中的颜如玉和科幻电影中的空中楼阁。一夜之间，它就降临到了所有人的身边，并不给你反应和拒绝的机会，连已经退休的父母都在微信中表示略有耳闻。

而对于软件、设计、写作行业的从业人员来说，这个冲击更是直直的迎在了面上。ChatGPT、Midjourney 等 AI 应用不仅改变了大家的工作方式，并在短短的半年内快速迭代，甚至开始影响和改变一些行业规则。

更多的人开始关注、了解和学习 AI，然而从上个世纪 1950 年就开始 AI 就开始萌芽，相关的概念和论文汗牛充栋。笔者虽然也是一名程序员，但大多数知识都在软件工程、应用开发上，在看到 AI 相关的各种概念，特别是各种分类、算法、专业词汇，也是一脸懵逼。因此在阅读了一些资料后，尝试用图解的方式重新整理 AI 的基本概念，从而找出适合自己的一条学习路径。

## AI 的应用领域

![](https://pic4.zhimg.com/80/v2-9d6ab07d82076ddae616b30cf1618a63_1440w.webp)

人工智能是一个存在已久的学科，其目标是研究使计算机能够模拟出人类的只能。而随着科技的发展（人类智力的发展），人工智能想要解决的问题也越来越多。但既然是模拟人，总逃不出 “眼、耳、嘴、大脑” 这些人用于接收和处理信息的感官系统。如果以解决的问题的角度划分，AI 可以分为几个应用领域：

- 问题域：AI 应该能解决哪些问题
  - CV 视觉能力
  - NLP 语言能力
  - VC 听觉能力
  - KG 思维和推理能力
- 复杂问题域：结合多种能力实现的复杂功能
- 自动驾驶、机器人、专家系统等
- 解决方案域：如何使 AI 有解决这些问题的能力
- 机器学习

## 机器学习策略

![](https://pic3.zhimg.com/80/v2-f8252582639800e30e15a7a731d68bca_1440w.webp)

由此我们可以看出，机器学习是让机器能够解决上述应用问题的解决方案。也是在漫长的发展和尝试中，我们得出几种相对靠谱的学习方式：

- 监督学习：对着课本进行教学
- 无监督学习：自学和自由阅读
- 强化学习：对学习成果予以奖励（和惩罚）
- 深度学习：大量的数据和神经网络的使用

各种学习方式并不是冲突的，只是对输入、输出和中间态的处理方式不同，演化到今天，大多数的机器学习都会叠加多种学习方式以实现更好的训练效果。如，使用标记好的数据作为输入，基于深度神经网络进行学习。

## 深度学习

![](https://pic4.zhimg.com/80/v2-1f471d7c7331603b1a08649595519dab_1440w.webp)

当我们的视角聚焦到深度学习时，我们终于捕捉到了生成式 AI、大语言模型这些最近比较火的名词。因为计算能力（CPU/GPU）的发展，通过神经网络训练的模型效果已经远远比其他学习方式来的强（所谓大力出奇迹）。

- 当训练数据、参数到达一定的数量级后，就形成了“大”模型
- 根据数据类型（输入输出）分为语言模型和图像模型（可以扩展为语音、视频模型）
- 区别于判别型 AI（这个图片是不是一只小狗），生成式 AI 可以根据训练数据输出新的内容

## LLM 大语言模型

![](https://pic4.zhimg.com/80/v2-772a3863c18267c3706c9d70d3bf4c37_1440w.webp)

大语言模型和生成式 AI 的划分维度是不一样的，一个是以输入数据的量级来看，另一个则是输出内容的模式。但应用了大语言模型的训练方式之后，生成式 AI 的能力得到了巨大的提升，由此诞生出了我们最近所看到的 ChatGPT、LLaMA 等模型。所以在现阶段，我们也常常说 LLM = GenAI。

LLM 的训练方式，还是逃不出监督、无监督、强化学习和神经网络。之前的科技发展不断叠加，才使得 LLM 在 2022/2023 爆炸式的成功。

(参照：[【精校版】Andrej Karpathy微软Build大会精彩演讲： GPT状态和原理 - 解密OpenAI模型训练\_哔哩哔哩\_bilibili](https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1ts4y1T7UH/)）

![](https://pic4.zhimg.com/80/v2-5d82f5e805af422ee8538b10a89517c3_1440w.webp)

LLM 的使用模式也因为 GenAI 的特性，和之前 is A==A 的模式有很大区别。我们可以用自然语言要求 AI “续写” 我们的任务 —— 即继续生成我们想要的但未给出的部分文字（或图像）。

因此我们也有了无需改变模型进行微调的方法，给出指向性前提和足够的 context 作为 prompt，即可影响 AI 的输出结果。

在图像模型上，还有 LoRA 技术可以在已有基础模型上进行叠加（比如，StableDiffusion），以调整模型的输出。

## 神经网络

![](https://pic2.zhimg.com/80/v2-b556b86a0c89af9c1f11d72728b279a1_1440w.webp)

深度学习的核心 —— 神经网络的基本模型其实非常简单，多层感知机和全连接模型也是上个世纪就提出的概念。但数据量上去之后，神经元的连接也是指数级的增加，需要非常多优化和调整才能由计算机进行处理。

![](https://pic4.zhimg.com/80/v2-b21431380163ff222a1726b727abea4f_1440w.webp)

DNN —— 想要表达更复杂的输入输出关系，要么增加参数、要么增加层数，“深度” 也就是这么来的，即增加神经网络的中间层数，来增加映射的多变性。

CNN —— 实际的神经元连接（推理计算）是邻接结构，即当前节点的值会受所有其他节点的影响，但这样的关系是无法被计算的。因此我们需要对节点关系进行采样滤波，只保留相关性更高的连接。

RNN —— 使上一次的输出状态参与计算，以便更好的处理一段文字、一段视频这种具有序列/时间相关的数据。
